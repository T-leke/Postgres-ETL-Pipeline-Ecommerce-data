#Extraction, Transformation and loading of an Ecommerce Data into PostgreSQL Database

This repository contains the code and resources to Extract, Transform & load data into a PostgreSQL database. The project involves data modeling, transformation, and final loading into the database using a Jupyter notebook.

## Repository Structure


## Files and Folders

- **dataset/**: This folder contains the transformed data that will be loaded into the PostgreSQL database.
  
- **.gitattributes**: Configuration file for managing attributes of the repository's contents.

- **data model.png**: An image of the data model for visual reference.
  
- **database model.drawio**: The data model created in draw.io, detailing the structure of the database tables and their relationships.
  
- **yanki_etl.ipynb**: The Jupyter notebook that contains the ETL (Extract, Transform, Load) process, which reads data, transforms it, and loads it into a PostgreSQL database.
  
- **.Sdatabase model.drawio.bkp**: A backup of the draw.io file containing the data model.
  
- **.Sdatabase model.drawio.dtmp**: A temporary file related to the draw.io file used for data modeling.

## Getting Started

To run this project locally, follow the steps below.

### Prerequisites

- **Python 3.x** installed on your system.
- **Jupyter Notebook** for running `.ipynb` files.
- **PostgreSQL Database** installed and configured.
- Required Python libraries (listed in `yanki_etl.ipynb`).

### Installation

1. **Clone the repository**:
   ```bash
   git clone https://github.com/yourusername/T-leke.git
   cd T-leke


